# AutoScaler <!-- omit in toc -->

> [Autoscaler](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md)

# 1. Opcional: Install kube-ops-view
```vim
git clone https://codeberg.org/hjacobs/kube-ops-view.git
kubectl apply -k kube-ops-view/deploy

kubectl port-forward service/kube-ops-view 8080:80

```
## 1.1. Instalar Nginx
```
sudo apt update
sudo apt install nginx -y
sudo vim /etc/nginx/sites-available/default
```
## 1.2. agregar la linea
```
    location / {
        proxy_pass http://localhost:8080;
    }
```
## 1.3. Reiniciar nginx
```
sudo nginx -s reload
```
## 1.4. Agregar puerto 80 al SG del bastion EKS
## 1.5. Probar en browser con ip pública del bastion EKS

# 2. Metrics
```vim
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

sudo apt install -y jq

kubectl get apiservice v1beta1.metrics.k8s.io -o json | jq '.status'

k get pods -n kube-system
k top nodes
k top pods
```
> "message": "all checks passed",



# 3. Configurar Cluster Autoscaler (CA)
## 3.1. CHECK ASG
```vim
export CLUSTER=<CLUSTER_NAME>
aws autoscaling \
    describe-auto-scaling-groups \
    --query "AutoScalingGroups[? Tags[? (Key=='eks:cluster-name') && Value=='${CLUSTER}']].[AutoScalingGroupName, MinSize, MaxSize,DesiredCapacity]" \
    --output table \
    --profile admin
```

## 3.2. Opcional manipular el ASG
```vim
export ASG_NAME=$(aws autoscaling describe-auto-scaling-groups --query "AutoScalingGroups[? Tags[? (Key=='eks:cluster-name') && Value=='${CLUSTER}']].AutoScalingGroupName" --output text  --profile admin)
echo $ASG_NAME

# Modificar la capacidad del ASG
aws autoscaling \
    update-auto-scaling-group \
    --auto-scaling-group-name ${ASG_NAME} \
    --min-size 1 \
    --desired-capacity 1 \
    --max-size 5 \
    --profile admin

# Check new values
aws autoscaling \
    describe-auto-scaling-groups \
    --query "AutoScalingGroups[? Tags[? (Key=='eks:cluster-name') && Value=='${CLUSTER}']].[AutoScalingGroupName, MinSize, MaxSize,DesiredCapacity]" \
    --output table \
    --profile admin
```

## 3.3. OIDC
```vim
eksctl utils associate-iam-oidc-provider \
    --cluster $CLUSTER \
    --approve \
    --profile eksctl
```
> IAM Open ID Connect provider is already associated with cluster "dev2" in "us-east-2"

## 3.4. Crear el archivo de configuración de la política: k8s-asg-policy.json
[policy](./assets/iam/k8s-asg-policy.json)


## 3.5. Policy & Role
```vim
aws iam create-policy   \
  --policy-name k8s-asg-policy \
  --policy-document file://k8s-asg-policy.json \
  --profile admin

export POLICY_ASG_ARN=$(aws iam list-policies --query 'Policies[?PolicyName==`k8s-asg-policy`].Arn' --output text --profile admin)
echo $POLICY_ASG_ARN

eksctl create iamserviceaccount \
    --name cluster-autoscaler \
    --namespace kube-system \
    --cluster $CLUSTER \
    --attach-policy-arn  $POLICY_ASG_ARN \
    --approve \
    --override-existing-serviceaccounts \
    --profile eksctl

kubectl -n kube-system describe sa cluster-autoscaler
```

>  created serviceaccount "kube-system/cluster-autoscaler"

## 3.6. Deploy CA: $CLUSTER
> [yaml](./assets/yaml/cluster-autoscaler.yaml)
```vim
# ---------------------> sustituir $CLUSTER var <---------------------

kubectl apply -f cluster-autoscaler.yaml

kubectl -n kube-system get deploy cluster-autoscaler

# prevenir la eliminación del nodo donde corre el pod CA
kubectl -n kube-system \
    annotate deployment.apps/cluster-autoscaler \
    cluster-autoscaler.kubernetes.io/safe-to-evict="false"

# latest docker image EKS version
export K8S_VERSION=$(kubectl version | grep 'Server Version:' | sed 's/[^0-9.]*\([0-9.]*\).*/\1/' | cut -d. -f1,2)

export AUTOSCALER_VERSION=$(curl -s "https://api.github.com/repos/kubernetes/autoscaler/releases" | grep '"tag_name":' | sed -s 's/.*-\([0-9][0-9\.]*\).*/\1/' | grep -m1 ${K8S_VERSION})

echo $AUTOSCALER_VERSION

kubectl -n kube-system \
    set image deployment.apps/cluster-autoscaler \
    cluster-autoscaler=us.gcr.io/k8s-artifacts-prod/autoscaling/cluster-autoscaler:v${AUTOSCALER_VERSION}

kubectl -n kube-system logs -f deployment/cluster-autoscaler

```


# 4. test HPA
> [Docs](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)


> [php example](./assets/yaml/php-apache.yaml)
```vim
kubectl apply -f php-apache.yaml
```
> rollingUpdate

> resources

> terminationGracePeriodSeconds


```
kubectl expose deploy php-apache --port 80

kubectl get pod -l app=php-apache

# Crear el HPA con CPU al 60%
kubectl autoscale deployment php-apache  \
    --cpu-percent=60\
    --min=1 \
    --max=15

kubectl get hpa
```
> [HPA yaml](./assets/yaml/hpa.yaml)

> php-apache   Deployment/php-apache   0%/50%          1         10        1          15s


## 4.1. Load
```vim
kubectl run -it load-generator --image=busybox
```

```
while true; do wget -q -O- http://php-apache; done
```
```
watch kubectl get hpa
```

# 5. Revisar pods "Pending"
# 6. Revisar logs de Cluster-autoscaler

# 7. Prueba. Eliminar un worker node manualmente desde la consola AWS
> Importante: eliminar unos de los workers NUEVOS, creados por cluster-autoscaler

> Auto-scaler crea un nuevo nodo para reemplazar el eliminado.

# 8. Práctica Opcional: Determinar el request y limit del pod: php-apache

## 8.1. Prerequisitos: ejecutar el pod de load-testing: HEY tool
```
kubectl run curl-testing --image=alpine/curl -- sleep 9000
kubectl exec -it curl-testing -- sh
apk add hey

hey -q 10 -c 2 -t 2 http://php-apache
```
- -z = tiempo de la prueba
- -q = cantidad de consultas (requests)
- -c = concurrencia (usuarios)
- -t = timeout

## 8.2. Prueba:
La aplicación php-apache debería soportar:
- 1000 request
- 25 usuarios
- 7 segundos de timeout
```
hey -q 1000 -c 25 -t 7 http://php-apache
```
## 8.3. Revisar el % de HPA
## 8.4. Revisar en Kube-Ops-View el consumo de CPU y Memoria
> El % de HPA CPU sube, pero en los worker nodes el CPU el consumo es de <20%

> Es posible monitorear los workers nodes con Grafana o Cloud Watch


## 8.5. Revisar la cantidad de request satisfactorios (200) y y los request por segundo
> Todos los request debe ser satisfactorios (200)


## 8.6. Ejecutar la prueba varias veces y comprobar el consumo de los pods
```
kubectl top pods
```
> Anotar las evidencias.

## 8.7. Ajustar el Request y Limit del POD según las evidencias

## 8.8. Ajustar el % de CPU del HPA: 95% CPU

## 8.9. Ejecutar la prueba varias veces y comprobar el consumo de los pods
> Todos los request debe ser satisfactorios (200)

## 8.10. Validar los "restarts" de los pods
> OOMKILLED: out of memory

## 8.11. Ajustar el limit de Memoria si es necesario

## 8.12. Cambiar el request de CPU a 250m con limit de 350m

## 8.13. Ejecutar la prueba varias veces y comprobar el consumo de los pods
> Todos los request debe ser satisfactorios (200)

## 8.14. Es posible que Cluster-autoscaler haya eliminado uno de los nodos para balancear la carga (workload)

## 8.15. Conclusión
- Request bajo: HPA creará la cantidad de PODS necesarios para asumir los requests y soportar los picos. Dinámica alta de creación/eliminación de PODS.
- Request al máximo: Worker nodes ociosos, pero con menos PODS en ejecución y sin picos. Hay posibilidad de crear worker nodes por pod pending (HPA)

# 9. Eliminar

```vim
kubectl delete hpa,svc php-apache

kubectl delete deployment php-apache

kubectl delete pod load-generator

kubeclt delete -f cluster-autoscaler.yaml
```

## 9.1. Eliminar EKS
## 9.2. Eliminar VM's
## 9.3. Eliminar EFS
## 9.4. Eliminar VPC
